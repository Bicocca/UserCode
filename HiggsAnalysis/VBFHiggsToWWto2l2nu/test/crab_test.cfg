[CRAB]
jobtype = cmssw
scheduler = glite
server_name = bari

[CMSSW]

### The data you want to access (to be found on DBS)

#datasetpath=/H130_WW_2l/Summer08_IDEAL_V9_v2/GEN-SIM-RECO
#datasetpath=/H150_WW_2l/Summer08_IDEAL_V9_v2/GEN-SIM-RECO
#datasetpath=/H160_WW_2l/Summer08_IDEAL_V9_v2/GEN-SIM-RECO
#datasetpath=/H170_WW_2l/Summer08_IDEAL_V9_v2/GEN-SIM-RECO
#datasetpath=/H200_WW_2l/Summer08_IDEAL_V9_v2/GEN-SIM-RECO
#datasetpath=/H500_WW_2l/Summer08_IDEAL_V9_v2/GEN-SIM-RECO

#datasetpath=/TauolaTTbar/Summer08_IDEAL_V9_v1/GEN-SIM-RECO
#datasetpath=/WW/Summer08_IDEAL_V9_v1/GEN-SIM-RECO
#datasetpath=/DYmumuM200/Summer08_IDEAL_V9_v1/GEN-SIM-RECO
#datasetpath=/DYmumuM500/Summer08_IDEAL_V9_v1/GEN-SIM-RECO
datasetpath=/Zee/Summer08_IDEAL_V9_v1/GEN-SIM-RECO
#datasetpath=/WJets-madgraph/Summer08_IDEAL_V11_redigi_v1/GEN-SIM-RECO
#datasetpath=/Exotica_Zee_M200/Summer08_IDEAL_V9_v1/GEN-SIM-RECO  

### The ParameterSet you want to use
pset=VBFHWW2l2nuSkim_cfg.py

### Splitting parameters
total_number_of_events=200000
#total_number_of_events=100
events_per_job = 5000
#number_of_jobs = 1

### The output files (comma separated list)
output_file = VBFHWW2l2nuTest.root

[USER] 
copy_data = 1
storage_element = srm-cms.cern.ch
storage_path = /srm/managerv2?SFN=/castor/cern.ch
#user_remote_dir=/user/a/amassiro/VBF/Skimmed/H130_WW_2l_Summer08_IDEAL_V9_v2/
#user_remote_dir=/user/a/amassiro/VBF/Skimmed/H150_WW_2l_Summer08_IDEAL_V9_v2/
#user_remote_dir=/user/a/amassiro/VBF/Skimmed/H160_WW_2l_Summer08_IDEAL_V9_v2/
#user_remote_dir=/user/a/amassiro/VBF/Skimmed/H170_WW_2l_Summer08_IDEAL_V9_v2/
#user_remote_dir=/user/a/amassiro/VBF/Skimmed/H200_WW_2l_Summer08_IDEAL_V9_v2/
#user_remote_dir=/user/a/amassiro/VBF/Skimmed/H500_WW_2l_Summer08_IDEAL_V9_v2/

#user_remote_dir=/user/a/amassiro/VBF/Skimmed/TauolaTTbar_Summer08_IDEAL_V9_v1/
#user_remote_dir=/user/a/amassiro/VBF/Skimmed/WW_Summer08_IDEAL_V9_v1/
#user_remote_dir=/user/a/amassiro/VBF/Skimmed/DYmumuM200_Summer08_IDEAL_V9_v1/
#user_remote_dir=/user/a/amassiro/VBF/Skimmed/DYmumuM500_Summer08_IDEAL_V9_v1/
user_remote_dir=/user/a/amassiro/VBF/Skimmed/Zee_Summer08_IDEAL_V9_v1/
#user_remote_dir=/user/a/amassiro/VBF/Skimmed/WJets-madgraph_Summer08_IDEAL_V11_redigi_v1/
#user_remote_dir=/user/a/amassiro/VBF/Skimmed/Exotica_Zee_M200_Summer08_IDEAL_V9_v1/

### OUTPUT files Management
##  output back into UI
return_data = 0

#if server
#thresholdLevel = 80
#eMail = andrea.massironi@cern.ch

[EDG]

## RB/WMS management:
rb = CERN

##  Black and White Lists management:
## By Storage
se_black_list = T0
#se_white_list =

## By ComputingElement
#ce_black_list =
#ce_white_list =

[CONDORG]

# Set this to condor to override the batchsystem defined in gridcat.
#batchsystem = condor

# Specify addition condor_g requirments
# use this requirment to run on a cms dedicated hardare
# globus_rsl = (condor_submit=(requirements 'ClusterName == \"CMS\" && (Arch == \"INTEL\" || Arch == \"X86_64\")'))
# use this requirement to run on the new hardware
#globus_rsl = (condor_submit=(requirements 'regexp(\"cms-*\",Machine)'))

